{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-FgJujttYX_s"
      },
      "outputs": [],
      "source": [
        "# Major parts of the code borrowed from: https://github.com/surabhisnath/aut-utility-prediction/blob/main/Main_Analysis_Script.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /Users/snath/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /Users/snath/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /Users/snath/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /Users/snath/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet as wn\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dyz2I7OT7LrL"
      },
      "outputs": [],
      "source": [
        "# Function for reading in Stevenson, 2020 data files and uniting rater_01 and rater_02 files\n",
        "def read_files(path):\n",
        "    \"\"\"\n",
        "    Read the csv files from ./data/Stevenson-2020-human\n",
        "\n",
        "    :param path: string with path to files\n",
        "    :return dataset: merged dataset\n",
        "    \"\"\"\n",
        "\n",
        "    path = path\n",
        "    all_files = glob.glob(path + \"/*.csv\")\n",
        "    liR1 = []\n",
        "    liR2 = []\n",
        "\n",
        "    for filename in all_files:\n",
        "        df = pd.read_csv(filename, index_col=None, header=0, nrows=1, encoding='latin1')\n",
        "        if len(df.columns) == 1:\n",
        "            df = pd.read_csv(filename, index_col=None, header=0, encoding='latin1', sep=';')\n",
        "        else:\n",
        "            df = pd.read_csv(filename, index_col=None, header=0, encoding='latin1')\n",
        "\n",
        "        if '_rater01' in filename:\n",
        "            liR1.append(df)\n",
        "\n",
        "\n",
        "        else:\n",
        "            liR2.append(df.loc[:, ['response_id', 'respondent_id', 'originality_rater02', 'utility_rater02']])\n",
        "\n",
        "    frameR1 = pd.concat(liR1, axis=0, ignore_index=True)\n",
        "    frameR2 = pd.concat(liR2, axis=0, ignore_index=True)\n",
        "\n",
        "    df = frameR1.merge(frameR2, on=['response_id','respondent_id'],\n",
        "                   how='left')\n",
        "\n",
        "    df[\"translated_response\"] = df[\"translated_response\"].astype(str)\n",
        "    df[\"response_id\"] = df[\"response_id\"].astype(str)\n",
        "    df[\"respondent_id\"] = df[\"respondent_id\"].astype(str)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Ensuring they are adjectives and at least 3 characters\n",
        "def is_adjective_and_long_enough(word):\n",
        "    return len(word) >= 3 and len(wn.synsets(word, pos=wn.ADJ)) > 0\n",
        "\n",
        "\n",
        "# Function for dropping invalid answers\n",
        "def drop_invalid(df):\n",
        "    \"\"\"\n",
        "    Drops all answers that were either empty, had a rating of 0 for at least one score,\n",
        "    or of which the respondent number was 9999 (indicating an invalid respondent)\n",
        "\n",
        "    :param df: dataset with all columns needed for further steps\n",
        "    :return dataset, dropped_data:  dataset without invalid data,\n",
        "                dataset of invalid data\n",
        "    \"\"\"\n",
        "    liV = [1] * len(df)\n",
        "    condition = (df[['utility_rater01', 'utility_rater02', 'originality_rater01', 'originality_rater02']] == 0).any(axis=1)\n",
        "\n",
        "    liV = [0 if cond else li for cond, li in zip(condition, liV)]\n",
        "\n",
        "    # Dropping answers rated as 0 by at least one rater\n",
        "    df['valid'] = liV\n",
        "    df_invalid = df[df['valid'] == 0]\n",
        "    df = df[df['valid'] != 0]\n",
        "\n",
        "    # Dropping respondent_id that seems to belong to no one\n",
        "    df_strange = df[df['respondent_id'] == 9999]\n",
        "    df = df[df['respondent_id'] != 9999]\n",
        "\n",
        "    # Dropping empty answers\n",
        "    df_empty = df[df['original_response'] == 'nan']\n",
        "    df = df[df['original_response'] != 'nan']\n",
        "    df = df.drop(columns=['valid'])\n",
        "\n",
        "    df_dropped = pd.concat([df_empty, df_strange, df_invalid], axis=0, ignore_index=True)\n",
        "\n",
        "    return df, df_dropped\n",
        "\n",
        "\n",
        "# Function for cleaning valid responses\n",
        "def clean_response(dataset, col_response):\n",
        "    \"\"\"\n",
        "    Function cleans the responses\n",
        "\n",
        "    :param dataset: dataset which include column(s) of responses\n",
        "    :param col_response: column name of responses to be cleaned\n",
        "    :return dataset: input dataset with clean responses added\n",
        "    \"\"\"\n",
        "    # Upper to lowercase, remove punctuation and redundant spaces/letters\n",
        "    dataset[col_response] = [x.lower() for x in dataset[col_response]]\n",
        "    dataset[col_response] = [re.sub(r'[^\\w\\s]', ' ', x) for x in dataset[col_response]]  # delete any signs\n",
        "    dataset[col_response] = [re.sub(r'\\b\\w\\b', ' ', x) for x in dataset[col_response]] # delete loose letters\n",
        "    dataset[col_response] = [x.strip() for x in dataset[col_response]]  # delete extra white space before/after string\n",
        "    dataset[col_response] = [' '.join(x.split()) for x in dataset[col_response]]  # delete every extra space in string\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loding data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-42ruafVA3G4"
      },
      "outputs": [],
      "source": [
        "# Reading in files where encoding needs to be detected (change file paths as needed)\n",
        "# with open('../data/Nath-2024-LLM.csv', 'rb') as f:\n",
        "#     result = chardet.detect(f.read())\n",
        "# df1 = pd.read_csv('../data/Nath-2024-LLM.csv', encoding=result['encoding'])\n",
        "\n",
        "# with open('../data/Hubert-2024-LLM.csv', 'rb') as f:\n",
        "#     result = chardet.detect(f.read())\n",
        "# df2 = pd.read_csv('../data/Hubert-2024-LLM.csv', encoding=result['encoding'])\n",
        "\n",
        "# Loading the rest of the data files (change file paths as needed)\n",
        "df3 = pd.read_csv('../data/Nath-2024-human.csv')\n",
        "df4 = pd.read_csv('../data/Stevenson-2022-human.csv')\n",
        "df5 = read_files('../data/Stevenson-2020-human')\n",
        "# df6 = pd.read_excel('../data/additional-LLM.xlsx')\n",
        "\n",
        "# Uniting all data files in one dataframe\n",
        "df = pd.concat([df3, df4, df5], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"research_id\" in df3.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akif1HKYVbzl"
      },
      "source": [
        "## Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aOqvD0dpagW6"
      },
      "outputs": [],
      "source": [
        "df['translated_response'] = df['translated_response'].astype(str)\n",
        "df, df_dropped = drop_invalid(df)\n",
        "df = clean_response(df, 'translated_response')\n",
        "\n",
        "# Surabhi additons\n",
        "df = df[[\"object\", \"translated_response\", \"utility_rater01\", \"utility_rater02\"]]\n",
        "df = df.drop_duplicates(subset=['object', 'translated_response']).reset_index(drop=True)\n",
        "df = df[(~pd.isna(df[\"utility_rater02\"])) & (~pd.isna(df[\"utility_rater01\"]))]\n",
        "df = df.rename(columns={\"object\": \"target object\", \"translated_response\": \"alternate use\", \"utility_rater01\": \"utility_r1\", \"utility_rater02\": \"utility_r2\"})\n",
        "df[\"mean_utility\"] = (df[\"utility_r1\"] + df[\"utility_r2\"])/2\n",
        "df = df.sort_values(by=[\"target object\"])\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"../data/aut.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
